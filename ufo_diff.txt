
研究下双向通信。比如一次性的发送2048个字节，但是收1024，然后继续发送字节了。是的。

python不止要返回connection，而是一个包含connectoin的线程对象了。

关于网络连接的全局保持。在服务端和客户端的区别？改如何如搞了？

# -*- coding: utf-8 -*-

timeout 等超时，是针对于connection设置，而不是tcp/socket层了。

上层业务把矛盾转移到下层，下层为上层提供接口了。

关于客户端的用法？还是说只要研究server服务端的用法？应该先研究服务端的用法就可以了。

thread 和 threading 函数。 ？？

此时的网络资源，以及server以及被复用？完成不同的角色了？middleware层，以及服务端，和客户端了。

必须是类的复用了？应该是吧。

复用的前提，是全局复用。比如说Tcpserver，等，然后对于request，调用我们自己的request了。然后利用之前已经写好的部分函数了。大致就是如此了。

写程序，规划算法和设计，确实会耗费很多的心血和思路。然而，这个就是我们所想要的了。是的。

connection的功能太过于简单，只有send不足以，实现我们发送文件的需要了。

首先就是自己可以构造各种的消息，甚至协议了。比如说nginx等。是的。

如果我们现在实现了字节流的发送了。那么我们下一步就是改实现发送url，发送header，发送body，发送param了。是的。把http协议搞一遍来。

还要发送各种的消息结构体了。是的。

自己写一套urllib的方式了。是的。采用我们自己的类了。是的。

这个是request，还有response呢？以及request的转发了？

在字节流的基础上，编写转发模块。以及response转发模块了。是的。

然后就可以完成proxy了。以及python的各种代理了？是的。

7010 为代理端口。

7011,7012,7013 为服务器端口了。作为参数进行传递过去了？应该是了。
~                                                                        
作为参数传递，以及rediscluster的例程是如何搞的？所以我们先写出来自己的，然后做一套流程了。是的。做一套参数解析的使用方式了。是的。以及配置解析了？是的。传递不同的配置文件，产生不同的例程了。这个更吊，比写参数好。配置文件，就是参数太多了，装不下后改为了，配置文件了。是的。

研究下swift的配置解析。是的。

渐进式的实现了技术积累了。

源码还是要读，才能扩展思路了。

走分布式的路线。然后去搞什么websocket的实现了。以及openflow协议等等。是的。

在写程序中，我们已经实现了什么功能，和我们要实现什么功能，这个就是理想和现实之区别了。

研究下载workers多个线程下，是如何实现分配的。比如开了多个进程了。是的。这个是如何搞的？进程克隆？

因此我的工作方式，就是不断在往前追了。所以王哥说的对，不往前看。因为还是在这个盘子上了。那么该怎么办？

轮训应该要比哈希慢，因为有锁了？因此挣钱不是因为目标，而是因为规则了。就像当前的深度学习，这个不是我们学习的目标了

而是应该是现实的规则了。因此，目标则是追的。但是现实的规则则是利用了。

首先使用address对于地址，进行链接。然后来缓存链接了。是的。

如果可以实现http request和response的转发，那就ok了。初步的计划就完成了。是的。

会写一个缓存服务器的，缓存页面，并用这个作为我们的爬虫的缓存服务器了。是的。参考nginx的方式了。是的。

增加多线程处理了。是的。同时处理多个request，而不是处理一个request了。是的。

下一步，重点关注下链接关闭的问题了。是的。

研究下nginx中反向链接是怎么搞的。

在客户端，发送http协议了。然后在服务端，尝试进行解析了。是的。

以及多线程处理了。是的。以及多worker的工作方式？端口不会冲突？

写一个继承Daemon 的线程版本不就好了。真是傻逼了。

发送http协议。解析http协议。尝试下。

解析一遍http协议，才能对于http协议，有个较为深刻的理解了。

request 的等待，需要客户端主动关闭链接，或者服务端关闭链接，如果不关闭，那么就会超时等待了。

完善负载均衡操作。后端连接swift server了。是的。完成所有的负载均衡的算法了。是的。

写一个orm，等。是的。以及其他了。是的。

轻量级cluster，高可用系统等。是的。利用负载均衡，构建高可用么？

nginx和redis的阅读整理。是的。

还是先写程序吧。是的。

研究httplib模块，网络的底层，是发出去后，如何接受的？

关于解析http代理，及其协议的基本思路。是，主动读，和主动写。而不是被动的方式了。是的。关于这个http_response的问题，自己就糊涂了。是的。以前是怎么想，根据形式，看起来，不像是自己主动去读的结果了。是的。所以就是等待了。现在开始重新理解http协议了。尤其是response和request。是的。

主动读recv，那么该如何主动的结束呢？以及读到buffer中去么？还是如何处理？

读socket，该如何结束呢？

所以http协议，明白何时读，而不是无限读的。是的。

如果读到消息头结束了。而没有content-length，那么就不读了。是的。

所以代理proxy，还是需要对于http进行解析的。

数据读写。就是网络描述符的读写了。要求一个读，一个写了。这个是如何处理的？就是文件描述符了。是的。那么拦截路由数据包，是怎么搞的？

网络监听。大致明白了。太几把危险。要爱人。是的。监听人的信息，对人不好。

网络socket。很重要，一为读，一为写。但是需要明白，何时读，何时写了。是的。准别写个nginx了。然后去搞分布式了？是的。

readlines 应该不会成立。毕竟没有close，没有结束符。

当读出Content-Length: 15 这个后，下一步，就不可继续读line了。需要去读长度了。是的。读漫15个字节后，就应该停止了。

因此，那么之前的问题，就是不知读到何时停止了。是的。不需要研究nginx。等自己写一个nginx的时候，自然一切都明白了。

某些关键的技术不明白，只是明白了大的流程，还是啥用也没有啊。

学习nginx的资料。学习其的相关模块。然后自己搞个封装。重新实现下，啥的。

写一个负载均衡+页面缓存器。应该就ok了。是的。不用server，一直的去读页面了。去读写磁盘了。是的。所以，这个是可以扩展到小文件上的么？把对于磁盘的寻址，改为对于nginx的寻址了。但是这个缓存和页面的缓存是不同的。但是可以作为小文件，小图片的缓存。是的。所以，关于视频流莫非就是这个了？应该是的。

研究呢，然后呢。可以改了。拿来就用了。但是模型分析，模型建立能力有么?没有，所以还是乖乖的从头写一遍吧。在这个过程中人的能力会有极大的提升了。

下一个目标就是cluster和高HA了。是的。

关于vcenterha的设计文档了。是的。研究一把，然后实现了。是的。从头到位的设计了。是的。

作为一个积累了。是的。

\\192.168.1.100\sync_15\share\upload\hechaoyi\文档

\\192.168.1.100\sync_15\share\upload\hechaoyi\文档

整理了70多个文档上传到以上目录。

包含
1.vAccess,vCenter，vServer的架构、功能设计、数据库设计等。
2.java,flex框架相关学习资料。
3.其他参考手册。
4.周良瀚整理的移动终端客户端交接文档。

研究下wsgi的分层。和继承了。是的。
