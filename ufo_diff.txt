
研究下双向通信。比如一次性的发送2048个字节，但是收1024，然后继续发送字节了。是的。

python不止要返回connection，而是一个包含connectoin的线程对象了。

关于网络连接的全局保持。在服务端和客户端的区别？改如何如搞了？

# -*- coding: utf-8 -*-

timeout 等超时，是针对于connection设置，而不是tcp/socket层了。

上层业务把矛盾转移到下层，下层为上层提供接口了。

关于客户端的用法？还是说只要研究server服务端的用法？应该先研究服务端的用法就可以了。

thread 和 threading 函数。 ？？

此时的网络资源，以及server以及被复用？完成不同的角色了？middleware层，以及服务端，和客户端了。

必须是类的复用了？应该是吧。

复用的前提，是全局复用。比如说Tcpserver，等，然后对于request，调用我们自己的request了。然后利用之前已经写好的部分函数了。大致就是如此了。

写程序，规划算法和设计，确实会耗费很多的心血和思路。然而，这个就是我们所想要的了。是的。

connection的功能太过于简单，只有send不足以，实现我们发送文件的需要了。

首先就是自己可以构造各种的消息，甚至协议了。比如说nginx等。是的。

如果我们现在实现了字节流的发送了。那么我们下一步就是改实现发送url，发送header，发送body，发送param了。是的。把http协议搞一遍来。

还要发送各种的消息结构体了。是的。

自己写一套urllib的方式了。是的。采用我们自己的类了。是的。

这个是request，还有response呢？以及request的转发了？

在字节流的基础上，编写转发模块。以及response转发模块了。是的。

然后就可以完成proxy了。以及python的各种代理了？是的。

7010 为代理端口。

7011,7012,7013 为服务器端口了。作为参数进行传递过去了？应该是了。
~                                                                        
作为参数传递，以及rediscluster的例程是如何搞的？所以我们先写出来自己的，然后做一套流程了。是的。做一套参数解析的使用方式了。是的。以及配置解析了？是的。传递不同的配置文件，产生不同的例程了。这个更吊，比写参数好。配置文件，就是参数太多了，装不下后改为了，配置文件了。是的。

研究下swift的配置解析。是的。

渐进式的实现了技术积累了。

源码还是要读，才能扩展思路了。

走分布式的路线。然后去搞什么websocket的实现了。以及openflow协议等等。是的。

在写程序中，我们已经实现了什么功能，和我们要实现什么功能，这个就是理想和现实之区别了。

研究下载workers多个线程下，是如何实现分配的。比如开了多个进程了。是的。这个是如何搞的？进程克隆？

因此我的工作方式，就是不断在往前追了。所以王哥说的对，不往前看。因为还是在这个盘子上了。那么该怎么办？

轮训应该要比哈希慢，因为有锁了？因此挣钱不是因为目标，而是因为规则了。就像当前的深度学习，这个不是我们学习的目标了

而是应该是现实的规则了。因此，目标则是追的。但是现实的规则则是利用了。

首先使用address对于地址，进行链接。然后来缓存链接了。是的。

如果可以实现http request和response的转发，那就ok了。初步的计划就完成了。是的。

会写一个缓存服务器的，缓存页面，并用这个作为我们的爬虫的缓存服务器了。是的。参考nginx的方式了。是的。

增加多线程处理了。是的。同时处理多个request，而不是处理一个request了。是的。

下一步，重点关注下链接关闭的问题了。是的。

研究下nginx中反向链接是怎么搞的。

在客户端，发送http协议了。然后在服务端，尝试进行解析了。是的。

以及多线程处理了。是的。以及多worker的工作方式？端口不会冲突？

写一个继承Daemon 的线程版本不就好了。真是傻逼了。

发送http协议。解析http协议。尝试下。

解析一遍http协议，才能对于http协议，有个较为深刻的理解了。

request 的等待，需要客户端主动关闭链接，或者服务端关闭链接，如果不关闭，那么就会超时等待了。

先读http协议的算法。 request 和response的算法。然后拦截浏览器的req了。是的。

把pynginx，支持所有的负载均衡算法。以及可以支持实际的流量拦截和使用了。是的。并做为流量拦截的基础了。是的。
